import operator
import os
from typing import Annotated, List, TypedDict

import yaml
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph

from app.engine import engine
from app.rag import rag_engine

# =============================================================================
# 1. Configuration & Utils (Persona Management)
# =============================================================================


def load_personas():
    """resources/personas.yaml íŒŒì¼ì—ì„œ ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    base_path = os.path.dirname(__file__)
    yaml_path = os.path.join(base_path, "../../resources/personas.yaml")

    if not os.path.exists(yaml_path):
        print(f"âš ï¸ Warning: Personas file not found at {yaml_path}. Using default.")
        raise FileNotFoundError(f"Personas file not found at {yaml_path}")

    with open(yaml_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


# ì•± ì‹œì‘ ì‹œ í˜ë¥´ì†Œë‚˜ ë¡œë“œ
PERSONA_CONFIG = load_personas()
print(f"âœ¨ Loaded personas: {list(PERSONA_CONFIG.keys())}")


def build_prompt(
    persona_key: str, task_instruction: str, context_data: str, user_query: str = ""
) -> str:
    """ê³µí†µ í”„ë¡¬í”„íŠ¸ ë¹Œë”: í˜ë¥´ì†Œë‚˜ í‚¤ì— ë§ì¶° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ë¦½í•©ë‹ˆë‹¤."""
    p = PERSONA_CONFIG.get(persona_key)
    if not p:
        p = PERSONA_CONFIG["rosy"]  # Fallback

    return f"""
You are {p["name"]}, {p["description"]}.
{task_instruction}

[Context/Info]
{context_data}

[Rules]
1. {p["style"]}
2. ALWAYS start your response with "{p["prefix"]}".

User Query: {user_query}
Answer:"""


# =============================================================================
# 2. State Definition
# =============================================================================


class AgentState(TypedDict):
    # messages: ëŒ€í™” ë‚´ì—­ (operator.addë¥¼ í†µí•´ ë¦¬ìŠ¤íŠ¸ê°€ ê³„ì† ëˆ„ì ë¨)
    messages: Annotated[List[dict], operator.add]
    current_intent: str
    final_response: str
    temperature: float  # ì—ì´ì „íŠ¸ë³„ ì°½ì˜ì„± ì¡°ì ˆì„ ìœ„í•œ íŒŒë¼ë¯¸í„°


# =============================================================================
# 3. Nodes (Agent Logic)
# =============================================================================


def classify_intent(state: AgentState):
    """LLM Router: ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í•¸ë“¤ëŸ¬ë¡œ ë¶„ë°°í•©ë‹ˆë‹¤."""
    last_msg = state["messages"][-1]["content"]

    # Few-shot Prompting for Classification
    prompt = f"""
You are an intent classifier for a burger shop chatbot.
Classify the user's message into ONE of the following categories:

1. HISTORY:
   - User asks about previous orders, bill, receipt, or "what did I order?".

2. ORDER:
   - User explicitly wants to ADD a specific item to the cart NOW (e.g., "I want a burger", "Add fries").
   - User has made a decision.

3. COMPLAINT:
   - User expresses dissatisfaction, anger, or asks for a manager/refund.
   - Keywords: "bad", "cold", "refund", "manager", "hate", "slow".

4. GENERAL:
   - User asks about menu, price, location, or just says "I want something..." without picking a specific item.
   - Greetings or general questions.

User Message: "{last_msg}"

Response (ONLY output the category name: HISTORY, ORDER, COMPLAINT, or GENERAL):"""

    # RouterëŠ” ì°½ì˜ì„±ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ temp=0.0 ì‚¬ìš©
    response = engine.generate_text(prompt, max_tokens=10, temperature=0.0)
    intent = response.strip().upper()

    if "HISTORY" in intent:
        final_intent = "history"
    elif "ORDER" in intent:
        final_intent = "order"
    elif "COMPLAINT" in intent:
        final_intent = "complaint"
    else:
        final_intent = "general"

    print(
        f"ğŸ§­ [LLM Router] '{last_msg}' -> AI Thought: {intent} -> Final: {final_intent}"
    )

    return {"current_intent": final_intent}


def handle_general(state: AgentState):
    """ì¼ë°˜ ëŒ€í™” -> Rosy (ì „ì²´ ê²€ìƒ‰)"""
    query = state["messages"][-1]["content"]

    # ì¼ë°˜ ì§ˆë¬¸ì€ ì „ì²´ ì •ë³´(ë©”ë‰´+ë§¤ì¥ì •ë³´) ê²€ìƒ‰
    docs = rag_engine.search(query)
    context = "\n".join(docs)

    prompt = build_prompt(
        persona_key="rosy",
        task_instruction="Answer the customer's question based ONLY on the info below.",
        context_data=context,
        user_query=query,
    )

    return {
        "final_response": prompt,
        "temperature": PERSONA_CONFIG["rosy"]["temperature"],
    }


def handle_order(state: AgentState):
    """ì£¼ë¬¸ ì²˜ë¦¬ -> Rosy (ë©”ë‰´íŒë§Œ ê²€ìƒ‰)"""
    query = state["messages"][-1]["content"]
    print(f"ğŸ” [Agent] Verifying Order against Menu DB: '{query}'")

    # ì£¼ë¬¸ ì‹œì—ëŠ” 'type: menu' ë°ì´í„°ë§Œ í•„í„°ë§í•˜ì—¬ ê²€ìƒ‰
    docs = rag_engine.search(query, filter={"type": "menu"})
    context = "\n".join(docs)

    task = """
The customer wants to order. Match the request to the OFFICIAL menu item name.
1. If found, accept the order and confirm the price.
2. If NOT found, apologize and suggest available items.
    """

    prompt = build_prompt(
        persona_key="rosy",
        task_instruction=task,
        context_data=context,
        user_query=query,
    )

    return {
        "final_response": prompt,
        "temperature": PERSONA_CONFIG["rosy"]["temperature"],
    }


def handle_complaint(state: AgentState):
    """ë¶ˆë§Œ ì ‘ìˆ˜ -> Gordon (ê·œì • ê²€ìƒ‰)"""
    query = state["messages"][-1]["content"]
    print("ğŸš¨ [Agent] Complaint detected! Switching to Manager Gordon.")

    # ê·œì •(Policy) ì •ë³´ ê²€ìƒ‰ (type: info)
    docs = rag_engine.search(query, filter={"type": "info"})
    context = "\n".join(docs)

    prompt = build_prompt(
        persona_key="gordon",
        task_instruction="Review the [Store Policy] below and respond professionally to the complaint.",
        context_data=context,
        user_query=query,
    )

    return {
        "final_response": prompt,
        "temperature": PERSONA_CONFIG["gordon"]["temperature"],
    }


def handle_history(state: AgentState):
    """ì£¼ë¬¸ ë‚´ì—­ í™•ì¸ -> Rosy (ê³„ì‚° ë° ìš”ì•½)"""
    # 1. ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
    history_lines = []
    # í˜„ì¬ ì§ˆë¬¸ì„ ì œì™¸í•œ ê³¼ê±° ê¸°ë¡ í™•ì¸
    past_messages = state["messages"][:-1]

    for msg in state["messages"]:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        if role == "user":
            history_lines.append(f"CUSTOMER: {content}")
        elif role == "assistant":
            history_lines.append(f"CLERK: {content}")

    conversation_text = "\n".join(history_lines)
    print(
        f"ğŸ“œ [History Context] (Length: {len(state['messages'])})\n{conversation_text}\n"
        + "-" * 20
    )

    p = PERSONA_CONFIG["rosy"]

    # ë°©ì–´ ë¡œì§: ì´ì „ ëŒ€í™”ê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
    if len(past_messages) == 0:
        return {
            "final_response": f"{p['prefix']}You haven't ordered anything yet! ğŸ“ How about trying our famous Gemma Classic? ğŸ”",
            "temperature": 0.7,
        }

    # 2. ìš”ì•½ í”„ë¡¬í”„íŠ¸
    prompt = f"""
You are {p["name"]}, {p["description"]}.
Task: Summarize the customer's order based ONLY on the history below.

[Conversation]
{conversation_text}

[Rules]
1. List only confirmed items (where CLERK said yes).
2. ALWAYS start your response with "{p["prefix"]}".
3. Output format example:
   "{p["prefix"]}Here is your order so far! ğŸ§¾
   - [Quantity]x [Item Name] ($[Unit Price])
   ----------------
   Total: $[Total Price]
   Is this correct? ğŸ˜Š"

Answer:"""

    # ê³„ì‚° ë° ìš”ì•½ì€ ì •í™•í•´ì•¼ í•˜ë¯€ë¡œ temperature=0.0
    return {"final_response": prompt, "temperature": 0.0}


# =============================================================================
# 4. Graph Construction
# =============================================================================

workflow = StateGraph(AgentState)

# ë…¸ë“œ ë“±ë¡
workflow.add_node("classify", classify_intent)
workflow.add_node("general_handler", handle_general)
workflow.add_node("order_handler", handle_order)
workflow.add_node("complaint_handler", handle_complaint)
workflow.add_node("history_handler", handle_history)

# ì‹œì‘ì  ì„¤ì •
workflow.set_entry_point("classify")


# ì¡°ê±´ë¶€ ì—£ì§€ (Router Logic)
def route_intent(state: AgentState):
    intent = state["current_intent"]
    if intent == "order":
        return "order_handler"
    elif intent == "history":
        return "history_handler"
    elif intent == "complaint":
        return "complaint_handler"
    return "general_handler"


workflow.add_conditional_edges(
    "classify",
    route_intent,
    {
        "order_handler": "order_handler",
        "history_handler": "history_handler",
        "complaint_handler": "complaint_handler",
        "general_handler": "general_handler",
    },
)

# ì¢…ë£Œ ì—£ì§€ ì„¤ì •
workflow.add_edge("general_handler", END)
workflow.add_edge("order_handler", END)
workflow.add_edge("complaint_handler", END)
workflow.add_edge("history_handler", END)

# ì²´í¬í¬ì¸í„°(ë©”ëª¨ë¦¬) ì„¤ì •
memory = MemorySaver()
agent_app = workflow.compile(checkpointer=memory)
